{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7679fee0",
   "metadata": {},
   "source": [
    "# Lab 4: Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are a class of neural networks that are particularly suited for sequential data. In this lab, we will explore the basics of RNNs, implement a simple RNN from scratch, and apply it to a sequence prediction task. One of the most common applications of RNNs is in natural language processing, where they can be used for tasks such as language modeling, text generation, and sentiment analysis.\n",
    "\n",
    "In this lab, we will briefly review the concept of RNNs, implement a simple RNN from scratch using PyTorch, and demonstrate how to use it for sequence prediction tasks. We will also explore how to handle sequential data using `Dataset` and `DataLoader`.\n",
    "\n",
    "## Introduction to RNNs\n",
    "\n",
    "RNNs are designed to handle sequential data by maintaining a hidden state that captures information from previous time steps. This allows them to learn dependencies in the data over time. The basic structure of an RNN consists of an input layer, a hidden layer, and an output layer. The hidden layer is recurrent, meaning that it takes both the current input and the previous hidden state as input.\n",
    "\n",
    "A simple RNN can be defined mathematically as follows:\n",
    "\n",
    "$$ h_t = f_w(h_{t-1}, x_t) $$\n",
    "\n",
    "where:\n",
    "\n",
    "| symbol | description |\n",
    "|--------|-------------|\n",
    "| $$ h_t $$ | new hidden state at time step \\( t \\), the output of the RNN at that time step |\n",
    "| $$ f_w $$ | function that computes the hidden state with parameters \\( w \\) |\n",
    "| $$ h_{t-1} $$ | old hidden state from the previous time step |\n",
    "| $$ x_t $$ | input vector at time step \\( t \\) |\n",
    "\n",
    "To process a sequence of inputs, the RNN iterates through each time step, updating its hidden state based on the current input and the previous hidden state. This allows the network to maintain a memory of past inputs, which is crucial for tasks that require understanding context over time.\n",
    "\n",
    "For example in a language modeling task, the RNN can learn to predict the next word in a sentence based on the words that have come before it. Consider the input sentence \"The cat sat on the mat.\" The RNN processes each word in the sentence sequentially, updating its hidden state to capture the context of the sentence as it progresses.\n",
    "\n",
    "---\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce124e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0379d8b1",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "Before diving into RNNs, it's important to understand embeddings, which are a way to represent words or tokens in a continuous vector space. This allows the model to capture semantic relationships between words. Word embeddings can be learned from data using techniques like Word2Vec, GloVe, or FastText, or they can be obtained from pre-trained models like BERT or GPT.\n",
    "\n",
    "## Understanding Word Embeddings\n",
    "\n",
    "In particular, we will use PyTorch's `nn.Embedding` class to create an embedding layer. This layer takes a vocabulary size and an embedding dimension as input and outputs the corresponding embeddings for the input tokens.\n",
    "\n",
    "## Implementation of Embedding Layer\n",
    "\n",
    "Let's implement a simple embedding layer using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad704c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple embedding layer\n",
    "class SimpleEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SimpleEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b4e9ed",
   "metadata": {},
   "source": [
    "In above code, we define a simple embedding layer using PyTorch's `nn.Embedding` class. This layer takes a vocabulary size and an embedding dimension as input and outputs the corresponding embeddings for the input tokens. The `forward` method applies the embedding layer to the input tensor `x`, which contains the indices of the tokens in the vocabulary.\n",
    "\n",
    "## Example Usage of the Embedding Layer\n",
    "\n",
    "To demonstrate how the embedding layer works, we can use a sample sentence and convert it into embeddings. Let's assume we have a vocabulary of size 10000 and an embedding dimension of 50. We can create a simple example as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c209a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output embeddings shape: torch.Size([9, 50])\n",
      "Output embeddings: tensor([[-0.2963, -0.6340, -0.3285, -0.6866,  2.8050, -0.4176, -0.2991,  0.1261,\n",
      "         -2.5564,  0.0357,  0.1976,  0.0407, -1.5840, -0.6216,  1.8142,  0.4543,\n",
      "         -0.1480, -0.1056, -1.3950, -1.3051,  0.1303,  1.5572, -1.3652, -0.0126,\n",
      "          0.7808, -2.0361, -1.3009,  0.0242, -0.0625,  0.3843, -0.6666, -0.7672,\n",
      "         -0.4212, -0.1538,  1.0725,  0.6273, -0.2252, -0.6387,  0.4487, -2.1970,\n",
      "          2.0449,  1.5520,  1.1275, -0.3182,  0.8463,  0.5343, -0.5538,  1.0649,\n",
      "         -0.3522, -0.2571],\n",
      "        [ 0.2715, -1.3029, -0.9057,  0.3579, -1.7064,  0.7636, -2.0855, -0.5252,\n",
      "          0.7536, -0.4373,  0.5272, -0.3707,  0.0800,  0.6728,  1.2277,  1.9393,\n",
      "          1.1930, -0.2834, -0.7333,  0.0278,  1.5018,  0.4754, -0.1076, -0.3920,\n",
      "          1.1594,  0.8735,  0.2560,  2.0067, -0.5472, -1.5595,  1.5067, -0.5563,\n",
      "         -1.4512,  0.4099,  2.3768,  2.1723,  0.0143, -0.2143,  0.4804,  0.7065,\n",
      "         -0.5686, -0.7263,  0.4826,  0.3818, -0.1782, -1.0711,  0.0995, -0.0646,\n",
      "          0.9559, -1.0138],\n",
      "        [-0.2009, -0.4150, -0.7826,  1.0431, -0.4519,  0.0512,  0.1536,  2.5296,\n",
      "         -0.2004,  2.1622,  0.1928, -0.1721,  0.8659, -1.3246, -0.3083,  0.8359,\n",
      "          0.6749, -1.9248, -1.0174,  2.2650, -0.9107,  0.7386,  0.3295,  0.8377,\n",
      "          0.8025, -1.0900, -0.2930, -1.0833, -0.4422, -0.0107,  1.2695, -1.1213,\n",
      "         -0.2672,  0.6737, -0.1089, -0.8213, -0.9295, -0.3857,  0.3235,  1.0315,\n",
      "         -0.1463,  0.1803,  0.3268,  0.2450,  0.3117, -1.0937,  1.1879,  0.9525,\n",
      "          0.8445,  0.6218],\n",
      "        [ 2.0290, -0.8587, -0.0345,  1.0874, -1.1749,  0.1943, -1.4874,  0.8213,\n",
      "          0.1921, -0.1641, -0.4462, -0.1251,  0.1272,  0.2395, -1.5818, -0.3287,\n",
      "          0.0171, -1.3220,  0.5913, -1.6460, -0.1416,  1.0158, -0.2647,  0.0075,\n",
      "          0.1705,  5.1505, -0.4893,  0.0699, -0.8599, -0.3462,  1.6092,  0.5934,\n",
      "          0.5724,  1.9928,  0.1558, -2.2774,  0.7923,  0.0971, -0.4152, -0.4877,\n",
      "         -1.0833,  0.5979, -0.8523,  0.4642,  2.1105, -0.0830,  2.4947,  0.0675,\n",
      "          0.0121, -2.1301],\n",
      "        [-0.4243, -1.2337, -0.6763,  2.2481, -0.2257, -0.0590,  0.7796, -0.5692,\n",
      "          0.2507, -1.0358, -0.2491, -0.4854, -0.2104,  0.3158,  0.1085, -0.3306,\n",
      "          0.5202,  0.6436, -0.9341,  0.7708,  1.3395, -1.1155,  0.0179, -2.0798,\n",
      "         -0.8920,  0.8700,  0.1526,  0.4688,  1.1678,  0.4032, -1.0135, -0.3424,\n",
      "         -1.0261,  1.0602,  0.4767, -1.0875,  0.8515, -0.7805,  1.1468, -1.7773,\n",
      "          0.9908, -0.4283, -0.1133,  0.8600, -1.2351,  0.0689, -0.7860,  0.7528,\n",
      "         -2.7979, -1.0697],\n",
      "        [ 1.7249,  0.4635, -0.8924,  0.3034, -1.6453, -1.4110,  0.5352,  0.1897,\n",
      "         -0.8461,  0.1894,  0.2471,  0.7146, -1.4456, -0.8854, -0.0643,  1.4662,\n",
      "          0.7615, -0.3661,  0.5834, -0.4491, -0.1363,  0.4557,  0.2591, -2.0110,\n",
      "         -0.5872,  0.0089,  0.0293, -1.7485, -0.6623,  0.8449,  1.4242,  0.1216,\n",
      "          0.2041, -0.3301, -0.6994,  0.9901,  1.2396,  1.8116, -0.1081, -0.4588,\n",
      "          0.5104,  0.1090, -1.5590,  0.1593, -0.6549,  0.6611, -1.2922,  1.3859,\n",
      "          0.6211,  0.2995],\n",
      "        [ 0.2514, -0.1279,  2.0344,  1.0817, -0.1330, -1.1070,  1.2454, -0.9988,\n",
      "         -1.5380, -0.8477,  0.2361, -0.0662, -0.0073,  0.4251, -1.1334, -0.3856,\n",
      "          1.2100,  0.4636, -0.8153,  0.6884, -1.4467,  0.3538, -0.5251, -0.5456,\n",
      "          0.4112,  0.0772,  0.2233, -1.3116, -0.6832,  0.4156, -0.9310,  0.6872,\n",
      "          0.2360,  1.6414, -0.8228, -0.6822,  0.4950,  0.3139,  0.0983,  0.3020,\n",
      "         -1.8374,  1.2105,  0.5411, -0.3022, -0.9776,  0.1987, -0.4093, -0.5784,\n",
      "          1.0645,  1.4300],\n",
      "        [ 0.7865, -0.0496, -0.5528, -0.5100,  0.0209,  0.2802, -0.4716, -0.6527,\n",
      "         -0.6720,  1.3141, -1.4736,  0.9114, -0.2090, -0.7134, -0.5022, -1.1350,\n",
      "          0.9039,  1.0187, -1.0310, -0.3978,  0.3368, -1.3768,  0.8457, -0.4323,\n",
      "         -0.7015, -0.2613, -1.2190, -0.2732, -0.7990,  0.0296,  0.0356, -0.5291,\n",
      "         -0.0955, -1.1689,  0.7702,  0.6923,  0.1664, -0.4359, -0.1881,  0.6697,\n",
      "          1.4564, -0.1874,  1.1358, -0.3179, -1.3310,  1.3116, -0.2124, -0.2928,\n",
      "         -0.5723,  1.6829],\n",
      "        [-0.4101,  0.8008,  0.0392, -0.7212,  1.8473, -0.8005,  1.6565, -1.2113,\n",
      "         -0.0911,  1.2224,  0.5738,  0.3267, -0.2098,  1.6011,  0.1205,  0.8201,\n",
      "         -0.8387, -0.3327,  1.0106, -0.1961, -2.5900, -0.0723, -0.8755, -0.3577,\n",
      "          0.9475, -0.4248, -1.2100,  0.9917, -0.1907,  0.8600, -1.1039, -0.7250,\n",
      "         -0.3140, -1.0921,  0.4508, -0.2292, -1.8484, -1.1308,  0.9957, -0.4326,\n",
      "          0.1800, -0.2343,  1.6306,  0.6014, -0.0789, -0.4987, -0.6604,  0.2959,\n",
      "          0.2941, -1.8387]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "vocab_size = 10000  # Example vocabulary size\n",
    "embedding_dim = 50  # Example embedding dimension\n",
    "embedding_layer = SimpleEmbedding(vocab_size, embedding_dim).to(device)\n",
    "sample_input = \"a quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# tokenize the input sentence\n",
    "tokens = sample_input.split()\n",
    "# create a mapping from tokens to indices\n",
    "token_to_index = {token: i for i, token in enumerate(set(tokens))}\n",
    "# convert tokens to indices\n",
    "input_indices = torch.tensor([token_to_index[token] for token in tokens], dtype=torch.long).to(device)\n",
    "\n",
    "output_embeddings = embedding_layer(input_indices)\n",
    "print(\"Output embeddings shape:\", output_embeddings.shape)\n",
    "print(\"Output embeddings:\", output_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbba93b",
   "metadata": {},
   "source": [
    "# Vanilla RNN\n",
    "\n",
    "Vanilla RNNs are a type of RNN that do not use any advanced techniques like LSTM or GRU. They are the simplest form of RNNs and can be implemented using basic PyTorch operations. In this section, we will implement a simple vanilla RNN from scratch using PyTorch's `nn.Module`.\n",
    "\n",
    "![Process sequences](https://calvinfeng.gitbook.io/machine-learning-notebook/~gitbook/image?url=https%3A%2F%2F760545131-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-legacy-files%2Fo%2Fassets%252F-LIA3amopGH9NC6Rf0mA%252F-LIA3mTJltflw3MVKAEQ%252F-LIA3nSKrqNJpLgASeso%252Fsequence.png%3Fgeneration%3D1532415397328022%26alt%3Dmedia&width=768&dpr=4&quality=100&sign=5baacf94&sv=2)\n",
    "\n",
    "Depeding on the task and input sequence, RNNs can be implemented in different ways. The most common configurations are:\n",
    "\n",
    "- One-to-One: The input sequence is a single vector, and the RNN produces a single output vector. This is typically used for tasks like sentiment analysis or classification.\n",
    "- One-to-Many: The input sequence is a single vector, and the RNN produces a sequence of output vectors. This is used for tasks like text generation or image captioning.\n",
    "- Many-to-One: The input sequence is a sequence of vectors, and the RNN produces a single output vector. This is used for tasks like video classification or sentiment analysis on a sequence of text.\n",
    "- Many-to-Many: The input sequence is a sequence of vectors, and the RNN produces a sequence of output vectors. This is used for tasks like machine translation or image captioning.\n",
    "\n",
    "A vanilla RNN could be implemented using PyTorch's `nn.Module` class without `nn.RNN`. Let's take a look in detail at how to implement a simple vanilla RNN from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19643314",
   "metadata": {},
   "source": [
    "## One-to-One RNN\n",
    "\n",
    "In a one-to-one RNN, the input sequence is a single vector, and the RNN produces a single output vector. It consists of a single input vector, a hidden state, and an output vector. The hidden state is updated based on the input vector, and the output vector is produced from the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98e1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneToOneRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(OneToOneRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.Wxh = nn.Linear(input_size, hidden_size)  # input to hidden\n",
    "        self.Whh = nn.Linear(hidden_size, hidden_size)  # hidden to hidden\n",
    "        self.Why = nn.Linear(hidden_size, output_size)  # hidden to output\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        h_prev = torch.tanh(self.Wxh(x) + self.Whh(h_prev))\n",
    "        y_t = self.Why(h_prev)\n",
    "        return y_t, h_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8528b3",
   "metadata": {},
   "source": [
    "The usage of a one-to-one RNN is similar to that of a feedforward neural network, where the input is processed through the RNN to produce an output. This type of RNN is often used for tasks like sentiment analysis or classification, where the input is a single vector (e.g., a fixed length sentence represented as a vector) and the output is a single vector (e.g., a sentiment score or class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d8faf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([[-0.6192, -0.6575,  1.0770,  0.6959,  1.2351, -0.3910, -1.1162, -1.1564,\n",
      "         -0.3809, -1.4583]])\n",
      "Output: tensor([[-0.0336,  0.4924,  0.1411, -0.0116,  0.3583]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example usage of OneToOneRNN\n",
    "input_size = 10  # Size of input vector\n",
    "hidden_size = 20  # Size of hidden state\n",
    "output_size = 5   # Size of output vector\n",
    "rnn = OneToOneRNN(input_size, hidden_size, output_size).to(device)\n",
    "x = torch.randn(1, input_size).to(device)  # Example input vector\n",
    "h_prev = torch.zeros(1, hidden_size).to(device)  # Initial hidden state\n",
    "output, h_next = rnn(x, h_prev)\n",
    "print(\"input: \", x)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa7e2c",
   "metadata": {},
   "source": [
    "## Many-to-One RNN\n",
    "\n",
    "In a many-to-one RNN, the input sequence is a sequence of vectors, and the RNN produces a single output vector. This is used for tasks like video classification or sentiment analysis on a sequence of text. The hidden state is updated at each time step based on the input vector, and the final hidden state is used to produce the output vector.\n",
    "\n",
    "The implementation of a many-to-one RNN is similar to that of a one-to-one RNN, but it processes a sequence of input vectors instead of a single vector. The final hidden state after processing the entire sequence is used to produce the output vector.\n",
    "\n",
    "The modification is highlighted below:\n",
    "\n",
    "```diff\n",
    "@@ -10 +10,2 @@\n",
    "-        h_prev = torch.tanh(self.Wxh(x) + self.Whh(h_prev))\n",
    "+        for t in range(x.size(0)):\n",
    "+            h_prev = torch.tanh(self.Wxh(x[t]) + self.Whh(h_prev))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c02c5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing a simple RNN without using nn.RNN\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.Wxh = nn.Linear(input_size, hidden_size)  # input to hidden\n",
    "        self.Whh = nn.Linear(hidden_size, hidden_size)  # hidden to hidden\n",
    "        self.Why = nn.Linear(hidden_size, output_size)  # hidden to output\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        # to handle sequences, we iterate over the inputs (time steps)\n",
    "        # x is expected to be of shape (seq_len, input_size)\n",
    "        for t in range(x.size(0)):\n",
    "            h_prev = torch.tanh(self.Wxh(x[t]) + self.Whh(h_prev))\n",
    "        y_t = self.Why(h_prev)\n",
    "        return y_t, h_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1803178",
   "metadata": {},
   "source": [
    "### Example Usage of the Many-to-One RNN layer\n",
    "\n",
    "To demonstrate how the RNN works, we can create a simple example where we process a sequence of inputs and compute the corresponding hidden states and outputs. The sample input is taken from the output embeddings of a previous embedding layer, and we will use a simple RNN to process this sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aa69e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  torch.Size([9, 50])\n",
      "Output: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = output_embeddings  # Get embeddings for the input indices\n",
    "input_size = embedding_dim  # Size of input vector\n",
    "hidden_size = 128  # Size of hidden state\n",
    "output_size = 2   # Size of output vector\n",
    "rnn = SimpleRNN(input_size, hidden_size, output_size).to(device)\n",
    "h_prev = torch.zeros(1, hidden_size).to(device)  # Initial hidden state\n",
    "output, h_next = rnn(x, h_prev)\n",
    "print(\"Input: \", x.shape)\n",
    "print(\"Output:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71e096",
   "metadata": {},
   "source": [
    "# Datasets and Data Loaders for sequential data\n",
    "\n",
    "To train our RNN, we need a dataset that consists of sequences. There are various datasets available for sequence prediction tasks, such as the Penn Treebank dataset for language modeling or the [IMDB dataset](https://ai.stanford.edu/~amaas/data/sentiment/) for sentiment analysis.\n",
    "\n",
    "## Downloading the Dataset\n",
    "\n",
    "Let's start by downloading the dataset with `curl` and extracting it with `tar`. We will use the IMDB dataset for sentiment analysis, which consists of movie reviews labeled as positive or negative.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5e104b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      " 10 80.2M   10 8784k    0     0  1951k      0  0:00:42  0:00:04  0:00:38 1951k\n",
      "gzip: stdin: unexpected end of file\n",
      "tar: Unexpected EOF in archive\n",
      "tar: Unexpected EOF in archive\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "!curl -Lo imdb.tar.gz https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf imdb.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07779960",
   "metadata": {},
   "source": [
    "Here we define two helper functions to load the IMDB dataset and its corresponding labels. The `load_imdb_data` function reads the dataset from the specified path and returns a list of tuples containing the text and label for each review. The label is `1` for positive reviews and `-1` for negative reviews. We also need to load the vocabulary from the `imdb.vocab` file, which contains the mapping of words to indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d08a7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after downloading the dataset, we define a function to load the IMDB dataset\n",
    "import os\n",
    "\n",
    "def load_imdb_data(path=\"./aclImdb\", split='train'):\n",
    "    if split not in ['train', 'test']:\n",
    "        raise ValueError(\"split must be either 'train' or 'test'\")\n",
    "    data = []\n",
    "    split_path = os.path.join(path, split)\n",
    "    for label in ['pos', 'neg']:\n",
    "        label_path = os.path.join(split_path, label)\n",
    "        for fname in os.listdir(label_path):\n",
    "            if fname.endswith('.txt'):\n",
    "                with open(os.path.join(label_path, fname), 'r', encoding='utf-8') as f:\n",
    "                    line = f.read().strip()\n",
    "                    data += [(1 if label == 'pos' else 0, line)]\n",
    "    return data\n",
    "\n",
    "def load_imdb_vocab(path=\"./aclImdb\"):\n",
    "    if not os.path.exists(os.path.join(path, 'imdb.vocab')):\n",
    "        raise FileNotFoundError(\"Vocabulary file not found in the specified path.\")\n",
    "    # Load the vocabulary from the imdb.vocab file\n",
    "    tokens = []\n",
    "    with open(os.path.join(path, 'imdb.vocab'), 'r', encoding='utf-8') as f:\n",
    "        tokens = [line.strip() for line in f.readlines()]\n",
    "    return tokens\n",
    "\n",
    "vocab_data = load_imdb_vocab(path=\"./aclImdb\")\n",
    "train_data = load_imdb_data(path=\"./aclImdb\", split='train')\n",
    "test_data = load_imdb_data(path=\"./aclImdb\", split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5193706",
   "metadata": {},
   "source": [
    "It's good to print out some basic statistics about the dataset, such as the number of reviews and the average length of the reviews. This will help us understand the dataset better and prepare for training our RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c24b0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 89527\n",
      "Number of training samples: 25000\n",
      "Number of testing samples: 25000\n",
      "Sample training data: (1, 'Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn\\'t really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I\\'d have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening.')\n",
      "Sample testing data: (1, \"Previous reviewer Claudio Carvalho gave a much better recap of the film's plot details than I could. What I recall mostly is that it was just so beautiful, in every sense - emotionally, visually, editorially - just gorgeous.<br /><br />If you like movies that are wonderful to look at, and also have emotional content to which that beauty is relevant, I think you will be glad to have seen this extraordinary and unusual work of art.<br /><br />On a scale of 1 to 10, I'd give it about an 8.75. The only reason I shy away from 9 is that it is a mood piece. If you are in the mood for a really artistic, very romantic film, then it's a 10. I definitely think it's a must-see, but none of us can be in that mood all the time, so, overall, 8.75.\")\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size:\", len(vocab_data))\n",
    "print(\"Number of training samples:\", len(train_data))\n",
    "print(\"Number of testing samples:\", len(test_data))\n",
    "\n",
    "print(\"Sample training data:\", train_data[0])\n",
    "print(\"Sample testing data:\", test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573fe281",
   "metadata": {},
   "source": [
    "## Defining a Custom Dataset Class\n",
    "\n",
    "After that, we define a custom dataset class that inherits from `torch.utils.data.Dataset`. This class will handle the tokenization of the input sequences and the conversion of tokens to indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8af8a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, sequences, vocab, device='cpu'):\n",
    "        self.sequences = sequences\n",
    "        self.vocab = vocab\n",
    "        self.device = device\n",
    "        self.token_to_index = {token: i for i, token in enumerate(vocab)}\n",
    "        self.index_to_token = {i: token for i, token in enumerate(vocab)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, line = self.sequences[idx]\n",
    "        target = torch.zeros(2, dtype=torch.float).to(self.device)\n",
    "        target[label] = 1.0  # one-hot encoding for binary classification\n",
    "        input_seq = torch.tensor([self.token_to_index[token] for token in self.tokenize(line) if token in self.vocab], dtype=torch.long).to(device)\n",
    "        return input_seq, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        text = text.lower().replace('.', '').replace(',', '')\n",
    "        return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a64c5bc",
   "metadata": {},
   "source": [
    "## Constructing the Dataloader\n",
    "\n",
    "To use our custom dataset class, we can create an instance of it and pass it to a `DataLoader`. The `DataLoader` will handle batching and shuffling of the data during training. For simplicity, we will use a batch size of 1 to avoid complications with padding and masking during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "67660573",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    SentimentDataset(train_data, vocab_data, device=device),\n",
    "    batch_size=1,\n",
    "    shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    SentimentDataset(test_data, vocab_data, device=device),\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ed416f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 439])\n",
      "Label: tensor([[0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_loader:\n",
    "    print(\"Input shape:\", inputs.shape)\n",
    "    print(\"Label:\", labels)\n",
    "    \n",
    "    break  # just to check the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b95f24",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "Before we can train our RNN, we need to construct the model for the binary classification task. We will use the previous simple RNN architecture with an embedding layer, an RNN layer, and a linear output layer.\n",
    "\n",
    "```mermaid\n",
    "flowchart TD;\n",
    "    A[Input Layer] --> B[Embedding Layer]\n",
    "    B --> C[RNN Layer]\n",
    "    C --> D[Output Layer]\n",
    "    C -->|Recurrent Connection| C\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f24a6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = SimpleEmbedding(vocab_size, embedding_dim)\n",
    "        self.rnn = SimpleRNN(input_size=embedding_dim, hidden_size=hidden_size, output_size=output_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        h_prev = torch.zeros(1, self.hidden_size)  # initial hidden state\n",
    "        rnn_output, h_prev = self.rnn(embedded, h_prev)\n",
    "        output = self.fc(h_prev)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d60f9a",
   "metadata": {},
   "source": [
    "## Construct the model, loss function, optimizer and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "25d56d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "learning_rate = 0.001\n",
    "embedding_size = 50\n",
    "\n",
    "# Construct the model, loss function, optimizer and parameters\n",
    "model = SentimentRNN(vocab_size=len(vocab_data), embedding_dim=embedding_size, hidden_size=128, output_size=2).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03cb6ae",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "In the training loop, we will iterate over the dataset for a specified number of epochs. For each batch, we will perform the following steps:\n",
    "1. Zero the gradients of the model parameters.\n",
    "2. Forward pass: Pass the input through the model to get the output.\n",
    "3. Compute the loss using the specified loss function.\n",
    "4. Backward pass: Compute the gradients of the loss with respect to the model parameters.\n",
    "5. Update the model parameters using the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953a599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/25000], Loss: 0.4456\n",
      "Epoch [1/5], Step [200/25000], Loss: 0.7368\n",
      "Epoch [1/5], Step [300/25000], Loss: 0.9745\n",
      "Epoch [1/5], Step [400/25000], Loss: 0.6506\n",
      "Epoch [1/5], Step [500/25000], Loss: 0.4566\n",
      "Epoch [1/5], Step [600/25000], Loss: 0.5874\n",
      "Epoch [1/5], Step [700/25000], Loss: 0.4563\n",
      "Epoch [1/5], Step [800/25000], Loss: 0.7857\n",
      "Epoch [1/5], Step [900/25000], Loss: 0.7775\n",
      "Epoch [1/5], Step [1000/25000], Loss: 0.6017\n",
      "Epoch [1/5], Step [1100/25000], Loss: 0.6524\n",
      "Epoch [1/5], Step [1200/25000], Loss: 0.4830\n",
      "Epoch [1/5], Step [1300/25000], Loss: 0.5055\n",
      "Epoch [1/5], Step [1400/25000], Loss: 1.0214\n",
      "Epoch [1/5], Step [1500/25000], Loss: 0.5068\n",
      "Epoch [1/5], Step [1600/25000], Loss: 0.8094\n",
      "Epoch [1/5], Step [1700/25000], Loss: 0.8628\n",
      "Epoch [1/5], Step [1800/25000], Loss: 0.7206\n",
      "Epoch [1/5], Step [1900/25000], Loss: 0.8552\n",
      "Epoch [1/5], Step [2000/25000], Loss: 0.6927\n",
      "Epoch [1/5], Step [2100/25000], Loss: 0.6084\n",
      "Epoch [1/5], Step [2200/25000], Loss: 0.4912\n",
      "Epoch [1/5], Step [2300/25000], Loss: 0.4808\n",
      "Epoch [1/5], Step [2400/25000], Loss: 0.4784\n",
      "Epoch [1/5], Step [2500/25000], Loss: 0.5812\n",
      "Epoch [1/5], Step [2600/25000], Loss: 0.6597\n"
     ]
    }
   ],
   "source": [
    "model.train() # Set the model to training mode\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.float().to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs.flatten())\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac653831",
   "metadata": {},
   "source": [
    "# Gradient vanishing and gradient explosion problem of Vanilla RNN\n",
    "\n",
    "Vanilla RNNs can suffer from the gradient vanishing and gradient explosion problems, which can make training difficult. The gradient vanishing problem occurs when the gradients become very small as they are propagated back through time, leading to slow or stalled learning. The gradient explosion problem occurs when the gradients become very large, causing the model parameters to diverge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78962fd3",
   "metadata": {},
   "source": [
    "## Demnonstration of the gradient vanishing\n",
    "\n",
    "To demonstrate the gradient vanishing problem, we can create a simple RNN with a large number of time steps and observe how the gradients behave during training. We will use a synthetic dataset with a long sequence length to illustrate this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ff97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic dataset with long sequences\n",
    "sequence_length = 1000  # Length of the sequence\n",
    "num_samples = 100  # Number of samples in the dataset\n",
    "input_size = 10  # Size of input vector\n",
    "hidden_size = 20  # Size of hidden state\n",
    "output_size = 5   # Size of output vector\n",
    "rnn = SimpleRNN(input_size, hidden_size, output_size).to(device)\n",
    "h_prev = torch.zeros(1, hidden_size).to(device)  # Initial hidden state\n",
    "for i in range(num_samples):\n",
    "    x = torch.randn(sequence_length, input_size).to(device)  # Example input sequence\n",
    "    output, h_next = rnn(x, h_prev)\n",
    "    loss = criterion(output, torch.randn(1, output_size).to(device))  # Random target for demonstration\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    print(f\"Sample {i+1}, Loss: {loss.item()}, Gradients: {rnn.Wxh.weight.grad.norm().item()}, {rnn.Whh.weight.grad.norm().item()}, {rnn.Why.weight.grad.norm().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c3f00",
   "metadata": {},
   "source": [
    "## Demnonstration of the gradient explosion\n",
    "\n",
    "To demonstrate the gradient explosion problem, we can create a simple RNN with a large number of time steps and observe how the gradients behave during training. We will use a synthetic dataset with a long sequence length to illustrate this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0abf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of the gradient explosion problem\n",
    "for i in range(num_samples):\n",
    "    x = torch.randn(sequence_length, input_size).to(device)  # Example input sequence\n",
    "    output, h_next = rnn(x, h_prev)\n",
    "    loss = criterion(output, torch.randn(1, output_size).to(device))  # Random target for demonstration\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    print(f\"Sample {i+1}, Loss: {loss.item()}, Gradients: {rnn.Wxh.weight.grad.norm().item()}, {rnn.Whh.weight.grad.norm().item()}, {rnn.Why.weight.grad.norm().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc91d4f",
   "metadata": {},
   "source": [
    "# Solving gradient vanishing and explosion with LSTM and GRU\n",
    "\n",
    "LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit) are advanced RNN architectures that are designed to address the gradient vanishing and explosion problems. They use gating mechanisms to control the flow of information through the network, allowing them to learn long-term dependencies more effectively.\n",
    "\n",
    "## LSTM\n",
    "\n",
    "LSTM is a type of RNN that uses a special gating mechanism to control the flow of information through the network. It consists of three gates: the input gate, the forget gate, and the output gate. These gates allow the LSTM to selectively remember or forget information from previous time steps, making it more effective at learning long-term dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e640b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = SimpleEmbedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM layer expects input of shape (batch_size, seq_len, input_size)\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_output, (h_n, c_n) = self.lstm(embedded)\n",
    "        output = self.fc(h_n)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31ea26",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "GRU (Gated Recurrent Unit) is another type of RNN that is similar to LSTM but has a simpler architecture. It uses two gates: the update gate and the reset gate. The update gate controls how much of the previous hidden state to keep, while the reset gate controls how much of the previous hidden state to forget. GRUs are often preferred over LSTMs due to their simpler structure and faster training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(SentimentGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = SimpleEmbedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # GRU layer expects input of shape (batch_size, seq_len, input_size)\n",
    "        embedded = self.embedding(x)\n",
    "        gru_output, h_n = self.gru(embedded)\n",
    "        output = self.fc(h_n)\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
